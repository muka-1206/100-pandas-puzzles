{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas パズル 100 問  - 解答 -\n",
    "\n",
    "[100 Numpy exerises](https://github.com/rougier/numpy-100) にインスパイアされ, [pandas](http://pandas.pydata.org/) の実力のテストのために １００ 問\\*の短いパズルを用意しました。\n",
    "\n",
    "pandas は多くのスペシャリストによって作り上げられてきた大きなライブラリですので、用意した問題は DataFrame と Series オブジェクトを使ったデータの操作に焦点を当てています。\n",
    "\n",
    "問題の多くは pandas または numpy の数行のコードで済むようなものです。正しい方法を選択し、練習することが目標となります。\n",
    "\n",
    "この問題集は大まかにいくつかのセクションに別れています。それぞれのセクションで難易度が異なりますが、それらの設定は主観的なものであり、おおよその指針と捉えるべきです。\n",
    "\n",
    "もしあなたがちょうど pandas を学び始めで、参考になる情報をお探しなら、公式ドキュメントがとてもオススメです。特に、pandas の概要を知りたいのであれば次のサイトをオススメします。\n",
    "- [10 minutes to pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "- [pandas basics](http://pandas.pydata.org/pandas-docs/stable/basics.html)\n",
    "- [tutorials](http://pandas.pydata.org/pandas-docs/stable/tutorials.html)\n",
    "- [cookbook and idioms](http://pandas.pydata.org/pandas-docs/stable/cookbook.html#cookbook)\n",
    "\n",
    "それでは、パズルを楽しんで!\n",
    "\n",
    "\\* 問題集は未完成です。問題のリクエストや提案、解答の修正に関することは歓迎します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas のインポート\n",
    "\n",
    "### pandas を読み込んでセットアップを確認しよう。\n",
    "\n",
    "難易度： *easy* \n",
    "\n",
    "**1.** `pd` の名前で pandas をインポートしなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** インポートした pandas のヴァージョンを表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** pandas ライブラリのすべてのヴァージョン情報を表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : None\n",
      "python           : 3.8.3.candidate.1\n",
      "python-bits      : 64\n",
      "OS               : Windows\n",
      "OS-release       : 10\n",
      "machine          : AMD64\n",
      "processor        : Intel64 Family 6 Model 142 Stepping 10, GenuineIntel\n",
      "byteorder        : little\n",
      "LC_ALL           : None\n",
      "LANG             : None\n",
      "LOCALE           : Japanese_Japan.932\n",
      "\n",
      "pandas           : 1.0.3\n",
      "numpy            : 1.18.4\n",
      "pytz             : 2020.1\n",
      "dateutil         : 2.8.1\n",
      "pip              : 20.1\n",
      "setuptools       : 46.1.3\n",
      "Cython           : None\n",
      "pytest           : None\n",
      "hypothesis       : None\n",
      "sphinx           : None\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : None\n",
      "lxml.etree       : None\n",
      "html5lib         : None\n",
      "pymysql          : None\n",
      "psycopg2         : None\n",
      "jinja2           : 2.11.2\n",
      "IPython          : 7.14.0\n",
      "pandas_datareader: None\n",
      "bs4              : None\n",
      "bottleneck       : None\n",
      "fastparquet      : None\n",
      "gcsfs            : None\n",
      "lxml.etree       : None\n",
      "matplotlib       : 3.2.1\n",
      "numexpr          : None\n",
      "odfpy            : None\n",
      "openpyxl         : None\n",
      "pandas_gbq       : None\n",
      "pyarrow          : None\n",
      "pytables         : None\n",
      "pytest           : None\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : 1.4.1\n",
      "sqlalchemy       : None\n",
      "tables           : None\n",
      "tabulate         : None\n",
      "xarray           : None\n",
      "xlrd             : None\n",
      "xlwt             : None\n",
      "xlsxwriter       : None\n",
      "numba            : None\n"
     ]
    }
   ],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame 基礎\n",
    "\n",
    "### DataFrame における選択、ソート、追加そして集計\n",
    "\n",
    "難易度: *easy*\n",
    "\n",
    "注意: numpy を使うときは次のようにすること。\n",
    "```python\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "以下のような辞書型の `data` およびリスト型の `labels` を考えましょう。\n",
    "\n",
    "``` python\n",
    "data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
    "        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n",
    "        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\n",
    "\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "```\n",
    "(これは作者が作った意味のないデータです。)\n",
    "\n",
    "**4.** `labels` をインデックスとして辞書型の `data` から DataFrame `df` を作りなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  animal  age  visits priority\n",
      "a    cat  2.5       1      yes\n",
      "b    cat  3.0       3      yes\n",
      "c  snake  0.5       2       no\n",
      "d    dog  NaN       3      yes\n",
      "e    dog  5.0       2       no\n",
      "f    cat  2.0       3       no\n",
      "g  snake  4.5       1       no\n",
      "h    cat  NaN       1      yes\n",
      "i    dog  7.0       2       no\n",
      "j    dog  3.0       1       no\n"
     ]
    }
   ],
   "source": [
    "data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
    "        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n",
    "        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\n",
    "\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "df = pd.DataFrame(data, index=labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n",
    "\n",
    "`class pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)`\n",
    "\n",
    "Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). Arithmetic operations align on both row and column labels. Can be thought of as a dict-like container for Series objects. The primary pandas data structure.\n",
    "\n",
    "    data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
    "    Dict can contain Series, arrays, constants, or list-like objects\n",
    "\n",
    "    If data is a dict, column order follows insertion-order for Python 3.6 and later.\n",
    "\n",
    "    If data is a list of dicts, column order follows insertion-order Python 3.6 and later.\n",
    "\n",
    "    index : Index or array-like\n",
    "    Index to use for resulting frame. Will default to RangeIndex if no indexing information part of input data and no index provided\n",
    "\n",
    "    columns : Index or array-like\n",
    "    Column labels to use for resulting frame. Will default to RangeIndex (0, 1, 2, …, n) if no column labels are provided\n",
    "\n",
    "    dtype : dtype, default None\n",
    "    Data type to force. Only a single dtype is allowed. If None, infer\n",
    "\n",
    "    copy : boolean, default False\n",
    "    Copy data from inputs. Only affects DataFrame / 2d ndarray input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** DataFrame と読み込んだデータについての基礎情報のサマリーを表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10 entries, a to j\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   animal    10 non-null     object \n",
      " 1   age       8 non-null      float64\n",
      " 2   visits    10 non-null     int64  \n",
      " 3   priority  10 non-null     object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 400.0+ bytes\n",
      "None\n",
      "            age     visits\n",
      "count  8.000000  10.000000\n",
      "mean   3.437500   1.900000\n",
      "std    2.007797   0.875595\n",
      "min    0.500000   1.000000\n",
      "25%    2.375000   1.000000\n",
      "50%    3.000000   2.000000\n",
      "75%    4.625000   2.750000\n",
      "max    7.000000   3.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** DataFrame `df` の最初の ３ 行を表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>age</th>\n",
       "      <th>visits</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>cat</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>cat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>snake</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal  age  visits priority\n",
       "a    cat  2.5       1      yes\n",
       "b    cat  3.0       3      yes\n",
       "c  snake  0.5       2       no"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:3, :]\n",
    "#df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** DataFrame `df` から 'animal' と 'age' カラムを選択して表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>cat</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>cat</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>snake</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>dog</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>dog</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>cat</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>snake</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>cat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>dog</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>dog</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal  age\n",
       "a    cat  2.5\n",
       "b    cat  3.0\n",
       "c  snake  0.5\n",
       "d    dog  NaN\n",
       "e    dog  5.0\n",
       "f    cat  2.0\n",
       "g  snake  4.5\n",
       "h    cat  NaN\n",
       "i    dog  7.0\n",
       "j    dog  3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['animal', 'age']]\n",
    "## 選択するカラムをリスト形式で渡すこと。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** `[3, 4, 8]` 行かつ `['animal', 'age']` カラムのデータを選択して表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>dog</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>dog</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>dog</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal  age\n",
       "d    dog  NaN\n",
       "e    dog  5.0\n",
       "i    dog  7.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.index[[3,4,8]], ['animal', 'age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** 'visits' が ２ より大きい行を選択して表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>age</th>\n",
       "      <th>visits</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>cat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>dog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>cat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal  age  visits priority\n",
       "b    cat  3.0       3      yes\n",
       "d    dog  NaN       3      yes\n",
       "f    cat  2.0       3       no"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['visits'] > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.** 'age' のデータが欠損している、すなわち `NaN` である行を選択して表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>age</th>\n",
       "      <th>visits</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>dog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>cat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal  age  visits priority\n",
       "d    dog  NaN       3      yes\n",
       "h    cat  NaN       1      yes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['age'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11.** 'animal' が cat で、かつ 'age' が ３ 未満である行を選択して表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>age</th>\n",
       "      <th>visits</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>cat</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>cat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal  age  visits priority\n",
       "a    cat  2.5       1      yes\n",
       "f    cat  2.0       3       no"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['animal']=='cat') & (df['age']<3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12.** 'age' が ２ 以上 4 以下である行を選択して表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>age</th>\n",
       "      <th>visits</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>cat</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>cat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>cat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>dog</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal  age  visits priority\n",
       "a    cat  2.5       1      yes\n",
       "b    cat  3.0       3      yes\n",
       "f    cat  2.0       3       no\n",
       "j    dog  3.0       1       no"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ df['age'].between(2, 4) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13.** 'f' 行の 'age' データを 1.5 に変更しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  animal  age  visits priority\n",
      "a    cat  2.5       1      yes\n",
      "b    cat  3.0       3      yes\n",
      "c  snake  0.5       2       no\n",
      "d    dog  NaN       3      yes\n",
      "e    dog  5.0       2       no\n",
      "f    cat  2.0       3       no\n",
      "g  snake  4.5       1       no\n",
      "h    cat  NaN       1      yes\n",
      "i    dog  7.0       2       no\n",
      "j    dog  3.0       1       no\n",
      "  animal  age  visits priority\n",
      "a    cat  2.5       1      yes\n",
      "b    cat  3.0       3      yes\n",
      "c  snake  0.5       2       no\n",
      "d    dog  NaN       3      yes\n",
      "e    dog  5.0       2       no\n",
      "f    cat  1.5       3       no\n",
      "g  snake  4.5       1       no\n",
      "h    cat  NaN       1      yes\n",
      "i    dog  7.0       2       no\n",
      "j    dog  3.0       1       no\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "df.loc['f', 'age'] = 1.5\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.** 'visits' のすべての和を計算しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['visits'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15.** それぞれの 'animal' の種類ごとに 'age' の平均を計算しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animal\n",
       "cat      2.333333\n",
       "dog      5.000000\n",
       "snake    2.500000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('animal')['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16.** DataFrame `df` に適当な値をもった 'k' 行を追加しなさい。その次に、その追加した行を削除しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  animal  age  visits priority\n",
      "a    cat  2.5       1      yes\n",
      "b    cat  3.0       3      yes\n",
      "c  snake  0.5       2       no\n",
      "d    dog  NaN       3      yes\n",
      "e    dog  5.0       2       no\n",
      "f    cat  1.5       3       no\n",
      "g  snake  4.5       1       no\n",
      "h    cat  NaN       1      yes\n",
      "i    dog  7.0       2       no\n",
      "j    dog  3.0       1       no\n",
      "k  snake  2.5       1       no\n",
      "  animal  age  visits priority\n",
      "a    cat  2.5       1      yes\n",
      "b    cat  3.0       3      yes\n",
      "c  snake  0.5       2       no\n",
      "d    dog  NaN       3      yes\n",
      "e    dog  5.0       2       no\n",
      "f    cat  1.5       3       no\n",
      "g  snake  4.5       1       no\n",
      "h    cat  NaN       1      yes\n",
      "i    dog  7.0       2       no\n",
      "j    dog  3.0       1       no\n"
     ]
    }
   ],
   "source": [
    "df.loc['k'] = ['snake', 2.5, 1, 'no']\n",
    "print(df)\n",
    "df = df.drop('k')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.drop` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)\n",
    "\n",
    "`DataFrame.drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')`\n",
    "\n",
    "Drop specified labels from rows or columns.\n",
    "\n",
    "Remove rows or columns by specifying label names and corresponding axis, or by specifying directly index or column names. When using a multi-index, labels on different levels can be removed by specifying the level.\n",
    "\n",
    "    labels : single label or list-like\n",
    "    Index or column labels to drop.\n",
    "\n",
    "    axis : {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "    Whether to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’).\n",
    "\n",
    "    index : single label or list-like\n",
    "    Alternative to specifying axis (labels, axis=0 is equivalent to index=labels).\n",
    "\n",
    "    New in version 0.21.0.\n",
    "\n",
    "    columns : single label or list-like\n",
    "    Alternative to specifying axis (labels, axis=1 is equivalent to columns=labels).\n",
    "\n",
    "    New in version 0.21.0.\n",
    "\n",
    "    level : int or level name, optional\n",
    "    For MultiIndex, level from which the labels will be removed.\n",
    "\n",
    "    inplace : bool, default False\n",
    "    If True, do operation inplace and return None.\n",
    "\n",
    "    errors : {‘ignore’, ‘raise’}, default ‘raise’\n",
    "    If ‘ignore’, suppress error and only existing labels are dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17.** 'animal' の種類の数を数えなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog      4\n",
       "cat      4\n",
       "snake    2\n",
       "Name: animal, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['animal'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.Series.value_counts` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html)\n",
    "\n",
    "`Series.value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)`\n",
    "\n",
    "Return a Series containing counts of unique values.\n",
    "\n",
    "The resulting object will be in descending order so that the first element is the most frequently-occurring element. Excludes NA values by default.\n",
    "\n",
    "    normalize : boolean, default False\n",
    "    If True then the object returned will contain the relative frequencies of the unique values.\n",
    "\n",
    "    sort : boolean, default True\n",
    "    Sort by frequencies.\n",
    "\n",
    "    ascending : boolean, default False\n",
    "    Sort in ascending order.\n",
    "\n",
    "    bins : integer, optional\n",
    "    Rather than count values, group them into half-open bins, a convenience for pd.cut, only works with numeric data.\n",
    "\n",
    "    dropna : boolean, default True\n",
    "    Don’t include counts of NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18.** DataFrame `df` を初めに 'age' カラムの値で降順にソートし、その次に 'visits' カラムの値で昇順にソートしなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>age</th>\n",
       "      <th>visits</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>dog</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>dog</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>snake</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>dog</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>cat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>cat</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>cat</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>snake</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>cat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>dog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal  age  visits priority\n",
       "i    dog  7.0       2       no\n",
       "e    dog  5.0       2       no\n",
       "g  snake  4.5       1       no\n",
       "j    dog  3.0       1       no\n",
       "b    cat  3.0       3      yes\n",
       "a    cat  2.5       1      yes\n",
       "f    cat  1.5       3       no\n",
       "c  snake  0.5       2       no\n",
       "h    cat  NaN       1      yes\n",
       "d    dog  NaN       3      yes"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.sort_index(by=['age', 'visits'], ascending=[False, True])\n",
    "df.sort_values(by=['age', 'visits'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**19.** 'priority' カラムは 'yes' と 'no' の値をもっている。このカラムの値に対して 'yes' を `True`、'no' を `False` で置き換えなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  animal  age  visits  priority\n",
      "a    cat  2.5       1      True\n",
      "b    cat  3.0       3      True\n",
      "c  snake  0.5       2     False\n",
      "d    dog  NaN       3      True\n",
      "e    dog  5.0       2     False\n",
      "f    cat  1.5       3     False\n",
      "g  snake  4.5       1     False\n",
      "h    cat  NaN       1      True\n",
      "i    dog  7.0       2     False\n",
      "j    dog  3.0       1     False\n"
     ]
    }
   ],
   "source": [
    "df['priority'] = df['priority'].map({'yes': True, 'no': False})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.Series.map [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html)\n",
    "\n",
    "Series.map(self, arg, na_action=None)\n",
    "\n",
    "Map values of Series according to input correspondence.\n",
    "\n",
    "Used for substituting each value in a Series with another value, that may be derived from a function, a `dict` or a `Series`.\n",
    "\n",
    "    arg : function, dict, or Series\n",
    "    Mapping correspondence.\n",
    "\n",
    "    na_action : {None, ‘ignore’}, default None\n",
    "    If ‘ignore’, propagate NaN values, without passing them to the mapping correspondence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20.** 'animal' カラムに対して、'snake' を 'python' に変更しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['animal'] = df['animal'].replace('snake', 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21.** それぞれの 'animal' の種類と 'visits' の回数に対して、'age' の平均を求めなさい。言い換えると、行が 'animal'、カラムが 'visits'、そして値が 'age' の平均である DataFrame を作りなさい。(ヒント： ピボットテーブルを使う。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-1ee3a63d67c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'animal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'visits'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\yuji.mukai\\documents\\training\\py_training\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mpivot_table\u001b[1;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed)\u001b[0m\n\u001b[0;32m   6068\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpivot_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6070\u001b[1;33m         return pivot_table(\n\u001b[0m\u001b[0;32m   6071\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6072\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yuji.mukai\\documents\\training\\py_training\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\u001b[0m in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mto_filter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age'"
     ]
    }
   ],
   "source": [
    "df.pivot_table(values='age', index='animal', columns='visits', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.pivot_table` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot_table.html)\n",
    "\n",
    "`DataFrame.pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False)`\n",
    "\n",
    "Create a spreadsheet-style pivot table as a DataFrame. The levels in the pivot table will be stored in MultiIndex objects (hierarchical indexes) on the index and columns of the result DataFrame.\n",
    "\n",
    "    values : column to aggregate, optional\n",
    "    index : column, Grouper, array, or list of the previous\n",
    "    If an array is passed, it must be the same length as the data. The list can contain any of the other types (except list). Keys to group by on the pivot table index. If an array is passed, it is being used as the same manner as column values.\n",
    "\n",
    "    columns : column, Grouper, array, or list of the previous\n",
    "    If an array is passed, it must be the same length as the data. The list can contain any of the other types (except list). Keys to group by on the pivot table column. If an array is passed, it is being used as the same manner as column values.\n",
    "\n",
    "    aggfunc : function, list of functions, dict, default numpy.mean\n",
    "    If list of functions passed, the resulting pivot table will have hierarchical columns whose top level are the function names (inferred from the function objects themselves) If dict is passed, the key is column to aggregate and value is function or list of functions\n",
    "\n",
    "    fill_value : scalar, default None\n",
    "    Value to replace missing values with\n",
    "\n",
    "    margins : boolean, default False\n",
    "    Add all row / columns (e.g. for subtotal / grand totals)\n",
    "\n",
    "    dropna : boolean, default True\n",
    "    Do not include columns whose entries are all NaN\n",
    "\n",
    "    margins_name : string, default ‘All’\n",
    "    Name of the row / column that will contain the totals when margins is True.\n",
    "\n",
    "    observed : boolean, default False\n",
    "    This only applies if any of the groupers are Categoricals. If True: only show observed values for categorical groupers. If False: show all values for categorical groupers.\n",
    "\n",
    "    Changed in version 0.25.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames: 基礎を学んだ人向け\n",
    "\n",
    "### ややトリッキー: 複数のメソッドを組み合わせて使う必要がある。\n",
    "\n",
    "難易度: *medium*\n",
    "\n",
    "前のセクションで扱った内容は基礎的だが必要不可欠な操作だった。以下では、データをカットするために必要になる手法を扱うが、すぐに使うことはないかもしれない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22.** 整数の入っている 'A' カラムをもっている DataFrame 'A' がある。例えば\n",
    "```python\n",
    "df = pd.DataFrame({'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7]})\n",
    "```\n",
    "\n",
    "すぐ上の行と同じ値をもつ行を取り除くにはどうすればいいですか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "3    3\n",
      "4    4\n",
      "5    5\n",
      "8    6\n",
      "9    7\n",
      "Name: A, dtype: int64\n",
      "\n",
      "   A\n",
      "0  1\n",
      "1  2\n",
      "3  3\n",
      "4  4\n",
      "5  5\n",
      "8  6\n",
      "9  7\n",
      "\n",
      "   A\n",
      "0  1\n",
      "3  3\n",
      "4  4\n",
      "8  6\n"
     ]
    }
   ],
   "source": [
    "print(df['A'].drop_duplicates())\n",
    "print()\n",
    "print(df.drop_duplicates(subset='A'))\n",
    "print()\n",
    "print(df.drop_duplicates(subset='A', keep=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.drop_duplicates` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
    "\n",
    "`DataFrame.drop_duplicates(self, subset=None, keep='first', inplace=False)`\n",
    "\n",
    "Return DataFrame with duplicate rows removed, optionally only considering certain columns. Indexes, including time indexes are ignored.\n",
    "\n",
    "    subset : column label or sequence of labels, optional\n",
    "    Only consider certain columns for identifying duplicates, by default use all of the columns\n",
    "\n",
    "    keep : {‘first’, ‘last’, False}, default ‘first’\n",
    "    first : Drop duplicates except for the first occurrence.\n",
    "    last : Drop duplicates except for the last occurrence.\n",
    "    False : Drop all duplicates.\n",
    "    inplace : boolean, default False\n",
    "    Whether to drop duplicates in place or to return a copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**23.** 次のような数値の DataFrame が与えられたとする。\n",
    "```python\n",
    "df = pd.DataFrame(np.random.random(size=(5, 3))) # 実数値を要素とする 5x3 の配列\n",
    "```\n",
    "それぞれの行の平均を対応する行のそれぞれの要素から差し引くにはどうすればいいですか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192252</td>\n",
       "      <td>0.036577</td>\n",
       "      <td>-0.228829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.259327</td>\n",
       "      <td>0.106661</td>\n",
       "      <td>0.152667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.025475</td>\n",
       "      <td>0.430798</td>\n",
       "      <td>-0.405323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.365268</td>\n",
       "      <td>-0.410243</td>\n",
       "      <td>0.044975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.400555</td>\n",
       "      <td>0.142320</td>\n",
       "      <td>0.258234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.192252  0.036577 -0.228829\n",
       "1 -0.259327  0.106661  0.152667\n",
       "2 -0.025475  0.430798 -0.405323\n",
       "3  0.365268 -0.410243  0.044975\n",
       "4 -0.400555  0.142320  0.258234"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.random((5, 3)))\n",
    "df.sub( df.mean(axis=1), axis=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas.DataFrame.mean(axis=0)` 列 (カラム) ごとに平均をとる\n",
    "- `pandas.DataFrame.mean(axis=1)` 行ごとに平均をとる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.sub` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sub.html)\n",
    "\n",
    "`DataFrame.sub(self, other, axis='columns', level=None, fill_value=None)`\n",
    "\n",
    "Get Subtraction of dataframe and other, element-wise (binary operator sub).\n",
    "\n",
    "Equivalent to `dataframe - other`, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, `rsub`.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, mod, pow) to arithmetic operators: +, -, \\*, /, //, %, \\*\\*.\n",
    "\n",
    "    other : scalar, sequence, Series, or DataFrame\n",
    "    Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "    axis : {0 or ‘index’, 1 or ‘columns’}\n",
    "    Whether to compare by the index (0 or ‘index’) or columns (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "    level : int or label\n",
    "    Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "    fill_value : float or None, default None\n",
    "    Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**24.** 実数の入っている 10 列の DataFrame があるとする。例えば\n",
    "```python\n",
    "df = pd.DataFrame(np.random.random(size=(5, 10)), columns=list('abcdefghij'))\n",
    "```\n",
    "どの列 (カラム) の和が最小か、その列のラベル (列の名前) を取得せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1.663970\n",
      "b    3.315396\n",
      "c    2.219191\n",
      "d    2.649228\n",
      "e    3.206379\n",
      "f    1.777875\n",
      "g    2.064203\n",
      "h    2.193731\n",
      "i    2.515843\n",
      "j    3.368839\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.random(size=(5, 10)), columns=list('abcdefghij'))\n",
    "print(df.sum(axis=0))\n",
    "df.sum(axis=0).idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**25.** DataFrame の中でユニークな行の数を知るにはどうすればいいか？ (すなわち、重複している行を無視しなさい。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  4  1\n",
      "1  1  0\n",
      "2  2  2\n",
      "3  2  1\n",
      "4  0  0\n",
      "5  3  2\n",
      "6  4  4\n",
      "7  0  3\n",
      "9  2  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(0,5,(10, 2)))\n",
    "#print(df)\n",
    "#print()\n",
    "print(df.drop_duplicates())\n",
    "len( df.drop_duplicates(keep=False) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas.DataFrame.drop_duplicates(keep=False)`  重複した行を全て落とす\n",
    "- `pandas.DataFrame.drop_duplicates(keep='first')`  重複した行で最初の行だけ残す\n",
    "- `pandas.DataFrame.drop_duplicates(keep='last')`  重複した行で最後の行だけ残す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次の 3 問は少し難しい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**26.** 浮動小数点数の入っている 10 列から成る DataFrame があり、各行には 5 つの NaN がそれぞれ含まれているとする。各行で左から 3 つめの NaN を含むカラムを探すにはどうすればいいか？ カラムのラベルを Series 形式で表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1        2         3         4         5         6  \\\n",
      "0       NaN  1.780497      NaN -1.637902       NaN  0.408207       NaN   \n",
      "1  1.032546       NaN -0.14357       NaN -1.618617       NaN -1.069066   \n",
      "2       NaN -0.094320      NaN -0.977447  1.295668       NaN -1.039906   \n",
      "\n",
      "          7         8         9  \n",
      "0  0.266723       NaN  2.058436  \n",
      "1       NaN -0.130077       NaN  \n",
      "2 -0.951007       NaN       NaN  \n",
      "\n",
      "0    4\n",
      "1    5\n",
      "2    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(3, 10))\n",
    "df.iloc[0, ::2] = np.nan\n",
    "df.iloc[1, 1::2] = np.nan\n",
    "df.iloc[2, [0, 2, 5, 8, 9]] = np.nan\n",
    "print(df)\n",
    "#print( df.isnull().cumsum(axis=1) == 3 ) \n",
    "print()\n",
    "print( (df.isnull().cumsum(axis=1) == 3).idxmax(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas.DataFrame.cumsum` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.cumsum.html)\n",
    "\n",
    "`DataFrame.cumsum(self, axis=None, skipna=True, *args, **kwargs)`\n",
    "\n",
    "Return cumulative sum over a DataFrame or Series axis.\n",
    "\n",
    "Returns a DataFrame or Series of the same size containing the cumulative sum.\n",
    "\n",
    "    axis : {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "    The index or the name of the axis. 0 is equivalent to None or ‘index’.\n",
    "\n",
    "    skipna : boolean, default True\n",
    "    Exclude NA/null values. If an entire row/column is NA, the result will be NA.\n",
    "\n",
    "    *args, **kwargs :\n",
    "    Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "- `pandas.DataFrame.idxmax` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html)\n",
    "\n",
    "`DataFrame.idxmax(self, axis=0, skipna=True)`\n",
    "\n",
    "Return index of **first occurrence of maximum** over requested axis. `NA/null` values are excluded.\n",
    "\n",
    "    axis : {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "    0 or ‘index’ for row-wise, 1 or ‘columns’ for column-wise\n",
    "\n",
    "    skipna : boolean, default True\n",
    "    Exclude NA/null values. If an entire row/column is NA, the result will be NA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**27.** ある DataFrame が 'grps' というカラム群と 'vals' という数値のカラム群から構成されている。例えば\n",
    "```python\n",
    "df = pd.DataFrame({'grps': list('aaabbcaabcccbbc'), \n",
    "                   'vals': [12,345,3,1,45,14,4,52,54,23,235,21,57,3,87]})\n",
    "```\n",
    "'grps' の要素の種類ごとに 'vals' を大きさの順に並べたとき、それぞれの 'grps' の種類で上位 3 つの和を取得しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'grps': list('aaabbcaabcccbbc'), \n",
    "                   'vals': [12,345,3,1,45,14,4,52,54,23,235,21,57,3,87]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grps\n",
      "a    409\n",
      "b    156\n",
      "c    345\n",
      "Name: vals, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print( df.groupby('grps')['vals'].nlargest(3) )\n",
    "print( df.groupby('grps')['vals'].nlargest(3).sum(level=0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas.DataFrame.nlargest` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nlargest.html)\n",
    "\n",
    "`DataFrame.nlargest(self, n, columns, keep='first')`\n",
    "\n",
    "Return the first `n` rows ordered by `columns` in descending order.\n",
    "\n",
    "Return the first `n` rows with the largest values in `columns`, in descending order. The columns that are not specified are returned as well, but not used for ordering.\n",
    "\n",
    "This method is equivalent to `df.sort_values(columns, ascending=False).head(n)`, but more performant.\n",
    "\n",
    "    n : int\n",
    "    Number of rows to return.\n",
    "\n",
    "    columns : label or list of labels\n",
    "    Column label(s) to order by.\n",
    "\n",
    "    keep : {‘first’, ‘last’, ‘all’}, default ‘first’\n",
    "    Where there are duplicate values:\n",
    "    - first : prioritize the first occurrence(s)\n",
    "    - last : prioritize the last occurrence(s)\n",
    "    - all : do not drop any duplicates, even it means\n",
    "    selecting more than n items.\n",
    "\n",
    "- `pandas.DataFrame.sum` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html)\n",
    "\n",
    "`DataFrame.sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)`\n",
    "\n",
    "Return the sum of the values for the requested axis.\n",
    "\n",
    "This is equivalent to the method `numpy.sum`.\n",
    "\n",
    "    axis : {index (0), columns (1)}\n",
    "    Axis for the function to be applied on.\n",
    "\n",
    "    skipna : bool, default True\n",
    "    Exclude NA/null values when computing the result.\n",
    "\n",
    "    level : int or level name, default None\n",
    "    If the axis is a MultiIndex (hierarchical), count along a particular level, collapsing into a Series.\n",
    "\n",
    "    numeric_only : bool, default None\n",
    "    Include only float, int, boolean columns. If None, will attempt to use everything, then use only numeric data. Not implemented for Series.\n",
    "\n",
    "    min_count : int, default 0\n",
    "    The required number of valid values to perform the operation. If fewer than min_count non-NA values are present the result will be NA.\n",
    "\n",
    "    New in version 0.22.0: Added with the default being 0. This means the sum of an all-NA or empty Series is 0, and the product of an all-NA or empty Series is 1.\n",
    "\n",
    "    **kwargs\n",
    "    Additional keyword arguments to be passed to the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**28.** 整数が入っている 2 つのカラム 'A' と 'B' があり、'A' は 1 以上 100 以下の値である。カラム 'A' を等間隔に 10 個のグループに分けたとき (すなわち `(0, 10]`, `(10, 20]`, ..., `(90, 100]` の １０ 群)、対応するカラム 'B' の和を計算しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "(0, 10]      1383\n",
      "(10, 20]     1896\n",
      "(20, 30]     1808\n",
      "(30, 40]     1230\n",
      "(40, 50]     1328\n",
      "(50, 60]      938\n",
      "(60, 70]     1368\n",
      "(70, 80]     1385\n",
      "(80, 90]     1382\n",
      "(90, 100]    2185\n",
      "Name: B, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(0, 100, (300, 2)), columns=['A', 'B'])\n",
    "#df.head()\n",
    "A_bin = pd.cut(df['A'], range(0, 101, 10))\n",
    "print( df.groupby(A_bin)['B'].sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.cut` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html)\n",
    "\n",
    "`pandas.cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False, duplicates='raise')`\n",
    "\n",
    "Bin values into discrete intervals.\n",
    "\n",
    "Use `cut` when you need to segment and sort data values into bins. This function is also useful for going from a continuous variable to a categorical variable. For example, `cut` could convert ages to groups of age ranges. Supports binning into an equal number of bins, or a pre-specified array of bins.\n",
    "\n",
    "    x : array-like\n",
    "    The input array to be binned. Must be 1-dimensional.\n",
    "\n",
    "    bins : int, sequence of scalars, or IntervalIndex\n",
    "    The criteria to bin by.\n",
    "\n",
    "    int : Defines the number of equal-width bins in the range of x. The range of x is extended by .1% on each side to include the minimum and maximum values of x.\n",
    "    sequence of scalars : Defines the bin edges allowing for non-uniform width. No extension of the range of x is done.\n",
    "    IntervalIndex : Defines the exact bins to be used. Note that IntervalIndex for bins must be non-overlapping.\n",
    "    right : bool, default True\n",
    "    Indicates whether bins includes the rightmost edge or not. If right == True (the default), then the bins [1, 2, 3, 4] indicate (1,2], (2,3], (3,4]. This argument is ignored when bins is an IntervalIndex.\n",
    "\n",
    "    labels : array or bool, optional\n",
    "    Specifies the labels for the returned bins. Must be the same length as the resulting bins. If False, returns only integer indicators of the bins. This affects the type of the output container (see below). This argument is ignored when bins is an IntervalIndex.\n",
    "\n",
    "    retbins : bool, default False\n",
    "    Whether to return the bins or not. Useful when bins is provided as a scalar.\n",
    "\n",
    "    precision : int, default 3\n",
    "    The precision at which to store and display the bins labels.\n",
    "\n",
    "    include_lowest : bool, default False\n",
    "    Whether the first interval should be left-inclusive or not.\n",
    "\n",
    "    duplicates : {default ‘raise’, ‘drop’}, optional\n",
    "    If bin edges are not unique, raise ValueError or drop non-uniques.\n",
    "\n",
    "    New in version 0.23.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames: 上級問題\n",
    "\n",
    "このセクションの問題は多少時間がかかるだろう。\n",
    "しかし、標準的な pandas/numpy のメソッドを使って解くことができる。(ただし for 文を使うことは避けてほしい。)\n",
    "\n",
    "難易度: *hard*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**29.** 次のようなカラム 'X' をもつ DataFrame を考える。\n",
    "```python\n",
    "df = pd.DataFrame({'X': [7, 2, 0, 3, 4, 2, 5, 0, 3, 4]})\n",
    "```\n",
    "カラム内のそれぞれの値に対して、自分より左側の直近の 0 または Series の左端のいずれかの近い方までの距離を数えなさい。解答としては `[1, 2, 0, 1, 2, 3, 4, 0, 1, 2]` が得られる。このようなカラム 'Y' を作りなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'X': [7, 2, 0, 3, 4, 2, 5, 0, 3, 4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4  5  6  7  8  9\n",
      "X  7  2  0  3  4  2  5  0  3  4\n",
      "Y  1  2  0  1  2  3  4  0  1  2\n"
     ]
    }
   ],
   "source": [
    "#print(df.T)\n",
    "#print()\n",
    "izero = np.r_[-1, (df['X'] == 0).to_numpy().nonzero()[0]] # 0 の位置のインデックス\n",
    "#print( (df['X'] == 0).to_numpy() )\n",
    "#print( (df['X'] == 0).to_numpy().nonzero() )\n",
    "#print( (df['X'] == 0).to_numpy().nonzero()[0] )\n",
    "#print( \"izero =\", izero )\n",
    "#print( \"izero - 1 =\", izero - 1)\n",
    "idx = np.arange(len(df))\n",
    "#print( \"idx =\", idx)\n",
    "df['Y'] = idx - izero[np.searchsorted(izero - 1, idx) - 1]\n",
    "#print( \"searchsorted =\", np.searchsorted(izero - 1, idx) )\n",
    "#print( izero[np.searchsorted(izero - 1, idx) - 1] )\n",
    "#print()\n",
    "print(df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `numpy.r_` [manual](https://docs.scipy.org/doc/numpy/reference/generated/numpy.r_.html)\n",
    "\n",
    "`numpy.r_ = <numpy.lib.index_tricks.RClass object>`\n",
    "\n",
    "Translates slice objects to concatenation along the first axis.\n",
    "\n",
    "This is a simple way to build up arrays quickly. There are two use cases.\n",
    "\n",
    "1. If the index expression contains comma separated arrays, then stack them along their first axis.\n",
    "1. If the index expression contains slice notation or scalars then create a 1-D array with a range indicated by the slice notation.\n",
    "\n",
    "If slice notation is used, the syntax `start:stop:step` is equivalent to `np.arange(start, stop, step)` inside of the brackets. However, if `step` is an imaginary number (i.e. 100j) then its integer portion is interpreted as a number-of-points desired and the start and stop are inclusive. In other words `start:stop:step` is interpreted as `np.linspace(start, stop, step, endpoint=1)` inside of the brackets. After expansion of slice notation, all comma separated sequences are concatenated together.\n",
    "\n",
    "Optional character strings placed as the first element of the index expression can be used to change the output. The strings ‘r’ or ‘c’ result in matrix output. If the result is 1-D and ‘r’ is specified a 1 x N (row) matrix is produced. If the result is 1-D and ‘c’ is specified, then a N x 1 (column) matrix is produced. If the result is 2-D then both provide the same matrix result.\n",
    "\n",
    "A string integer specifies which axis to stack multiple comma separated arrays along. A string of two comma-separated integers allows indication of the minimum number of dimensions to force each entry into as the second integer (the axis to concatenate along is still the first integer).\n",
    "\n",
    "A string with three comma-separated integers allows specification of the axis to concatenate along, the minimum number of dimensions to force the entries to, and which axis should contain the start of the arrays which are less than the specified number of dimensions. In other words the third integer allows you to specify where the 1’s should be placed in the shape of the arrays that have their shapes upgraded. By default, they are placed in the front of the shape tuple. The third argument allows you to specify where the start of the array should be instead. Thus, a third argument of ‘0’ would place the 1’s at the end of the array shape. Negative integers specify where in the new shape tuple the last dimension of upgraded arrays should be placed, so the default is ‘-1’.\n",
    "\n",
    "- `numpy.searchsorted` [manual]()\n",
    "\n",
    "`numpy.searchsorted(a, v, side='left', sorter=None)`\n",
    "\n",
    "Find indices where elements should be inserted to maintain order.\n",
    "\n",
    "Find the indices into a sorted array a such that, if the corresponding elements in v were inserted before the indices, the order of a would be preserved.\n",
    "\n",
    "Assuming that a is sorted:\n",
    "\n",
    "    side\treturned index i satisfies\n",
    "    left\ta[i-1] < v <= a[i]\n",
    "    right\ta[i-1] <= v < a[i]\n",
    "    \n",
    "    a : 1-D array_like\n",
    "    Input array. If sorter is None, then it must be sorted in ascending order, otherwise sorter must be an array of indices that sort it.\n",
    "\n",
    "    v : array_like\n",
    "    Values to insert into a.\n",
    "\n",
    "    side : {‘left’, ‘right’}, optional\n",
    "    If ‘left’, the index of the first suitable location found is given. If ‘right’, return the last such index. If there is no suitable index, return either 0 or N (where N is the length of a).\n",
    "\n",
    "    sorter : 1-D array_like, optional\n",
    "    Optional array of integer indices that sort array a into ascending order. They are typically the result of argsort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an alternative approach based on a [cookbook recipe](http://pandas.pydata.org/pandas-docs/stable/cookbook.html#grouping):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**30.** 数値データだけが入っている DataFrame を考える。大きさの順で上位 ３ つの値の入っている場所の行 row と列 column のインデックスを取得しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  7    0.960025\n",
      "1  3    0.963125\n",
      "7  7    0.974246\n",
      "dtype: float64\n",
      "[(9, 7), (1, 3), (7, 7)]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.random((10, 10)))\n",
    "#print( df.unstack() )\n",
    "#print( df.unstack().sort_values()[-3] )\n",
    "print( df.unstack().sort_values()[-3:] )\n",
    "print( df.unstack().sort_values()[-3:].index.tolist() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas.DataFrame.unstack` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.unstack.html)\n",
    "\n",
    "`DataFrame.unstack(self, level=-1, fill_value=None)`\n",
    "\n",
    "Pivot a level of the (necessarily hierarchical) index labels, returning a DataFrame having a new level of column labels whose inner-most level consists of the pivoted index labels.\n",
    "\n",
    "If the index is not a MultiIndex, the output will be a Series (the analogue of stack when the columns are not a MultiIndex).\n",
    "\n",
    "The level involved will automatically get sorted.\n",
    "\n",
    "    level : int, string, or list of these, default -1 (last level)\n",
    "    Level(s) of index to unstack, can pass level name\n",
    "\n",
    "    fill_value : replace NaN with this value if the unstack produces\n",
    "    missing values\n",
    "\n",
    "- `pandas.DataFrame.sort_values` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html)\n",
    "\n",
    "`DataFrame.sort_values(self, by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')`\n",
    "\n",
    "Sort by the values along either axis.\n",
    "\n",
    "    by : str or list of str\n",
    "    Name or list of names to sort by.\n",
    "\n",
    "    if axis is 0 or ‘index’ then by may contain index levels and/or column labels\n",
    "    if axis is 1 or ‘columns’ then by may contain column levels and/or index labels\n",
    "    Changed in version 0.23.0: Allow specifying index or column level names.\n",
    "\n",
    "    axis : {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "    Axis to be sorted.\n",
    "\n",
    "    ascending : bool or list of bool, default True\n",
    "    Sort ascending vs. descending. Specify list for multiple sort orders. If this is a list of bools, must match the length of the by.\n",
    "\n",
    "    inplace : bool, default False\n",
    "    If True, perform operation in-place.\n",
    "\n",
    "    kind : {‘quicksort’, ‘mergesort’, ‘heapsort’}, default ‘quicksort’\n",
    "    Choice of sorting algorithm. See also ndarray.np.sort for more information. mergesort is the only stable algorithm. For DataFrames, this option is only applied when sorting on a single column or label.\n",
    "\n",
    "    na_position : {‘first’, ‘last’}, default ‘last’\n",
    "    Puts NaNs at the beginning if first; last puts NaNs at the end.\n",
    "\n",
    "- `pandas.Index.tolist` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.tolist.html)\n",
    "\n",
    "`Index.tolist(self)`\n",
    "\n",
    "Return a list of the values.\n",
    "\n",
    "These are each a scalar type, which is a Python scalar (for str, int, float) or a pandas scalar (for Timestamp/Timedelta/Interval/Period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**31.** 'grps' というグループ ID をもつカラムと整数の入った 'vals' というカラムをもつ DataFrame がある。'grps' ごとに値をまとめたとき、'vals' が負であるものを 'grps' ごとの平均で置き換えなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'grps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-a00e542803a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'grps'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vals'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\yuji.mukai\\documents\\training\\py_training\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\u001b[0m\n\u001b[0;32m   5799\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5801\u001b[1;33m         return groupby_generic.DataFrameGroupBy(\n\u001b[0m\u001b[0;32m   5802\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5803\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yuji.mukai\\documents\\training\\py_training\\.venv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[0;32m    403\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yuji.mukai\\documents\\training\\py_training\\.venv\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[0;32m    596\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'grps'"
     ]
    }
   ],
   "source": [
    "def replace(group):\n",
    "    mask = group < 0\n",
    "    group[mask] = group[~mask].mean()\n",
    "    return group\n",
    "\n",
    "df.groupby('grps')['vals'].transform(replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.transform` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transform.html)\n",
    "\n",
    "`DataFrame.transform(self, func, axis=0, *args, **kwargs)`\n",
    "\n",
    "Call func on self producing a DataFrame with transformed values and that has the same axis length as self.\n",
    "\n",
    "    func : function, str, list or dict\n",
    "    Function to use for transforming the data. If a function, must either work when passed a DataFrame or when passed to DataFrame.apply.\n",
    "\n",
    "    Accepted combinations are:\n",
    "    - function\n",
    "    - string function name\n",
    "    - list of functions and/or function names, e.g. [np.exp. 'sqrt']\n",
    "    - dict of axis labels -> functions, function names or list of such.\n",
    "\n",
    "    axis : {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "    If 0 or ‘index’: apply function to each column. If 1 or ‘columns’: apply function to each row.\n",
    "\n",
    "    *args\n",
    "    Positional arguments to pass to func.\n",
    "\n",
    "    **kwargs\n",
    "    Keyword arguments to pass to func."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**32.** 次の DataFrame について、ウィンドー幅が 3 の移動平均を実装しなさい。ただし、 NaN は無視しなさい。\n",
    "```python\n",
    ">>> df = pd.DataFrame({'group': list('aabbabbbabab'),\n",
    "                       'value': [1, 2, 3, np.nan, 2, 3, np.nan, 1, 7, 3, np.nan, 8]})\n",
    ">>> df\n",
    "   group  value\n",
    "0      a    1.0\n",
    "1      a    2.0\n",
    "2      b    3.0\n",
    "3      b    NaN\n",
    "4      a    2.0\n",
    "5      b    3.0\n",
    "6      b    NaN\n",
    "7      b    1.0\n",
    "8      a    7.0\n",
    "9      b    3.0\n",
    "10     a    NaN\n",
    "11     b    8.0\n",
    "```\n",
    "答えは次のようにしてほしい。\n",
    "```\n",
    "0     1.000000\n",
    "1     1.500000\n",
    "2     3.000000\n",
    "3     3.000000\n",
    "4     1.666667\n",
    "5     3.000000\n",
    "6     3.000000\n",
    "7     2.000000\n",
    "8     3.666667\n",
    "9     2.000000\n",
    "10    4.500000\n",
    "11    4.000000\n",
    "```\n",
    "すなわち、幅 3 のウィンドーので groub 'b' に対する最初のウィンドーは 3.0, NaN, そして 3.0 で、それらの平均がインデックス 5 の行の位置で返される。NaN がある場合は無視して計算する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'group': list('aabbabbbabab'),\n",
    "                   'value': [1, 2, 3, np.nan, 2, 3, np.nan, 1, 7, 3, np.nan, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n",
    "g1 = df.groupby('group')['value']\n",
    "g2 = df.fillna(0).groupby('group')['value']\n",
    "m = g2.rolling(3, min_periods=1).sum() / g1.rolling(3, min_periods=1).count()\n",
    "#print(m)\n",
    "print( m.reset_index(level=0, drop=False).sort_index() )\n",
    "print()\n",
    "print( m.reset_index(level=0, drop=True).sort_index() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas.DataFrame.rolling` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html)\n",
    "\n",
    "`DataFrame.rolling(self, window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None)`\n",
    "\n",
    "Provide rolling window calculations.\n",
    "\n",
    "    window : int, or offset\n",
    "    Size of the moving window. This is the number of observations used for calculating the statistic. Each window will be a fixed size.\n",
    "\n",
    "    If its an offset then this will be the time period of each window. Each window will be a variable sized based on the observations included in the time-period. This is only valid for datetimelike indexes. This is new in 0.19.0\n",
    "\n",
    "    min_periods : int, default None\n",
    "    Minimum number of observations in window required to have a value (otherwise result is NA). For a window that is specified by an offset, min_periods will default to 1. Otherwise, min_periods will default to the size of the window.\n",
    "\n",
    "    center : bool, default False\n",
    "    Set the labels at the center of the window.\n",
    "\n",
    "    win_type : str, default None\n",
    "    Provide a window type. If None, all points are evenly weighted. See the notes below for further information.\n",
    "\n",
    "    on : str, optional\n",
    "    For a DataFrame, a datetime-like column on which to calculate the rolling window, rather than the DataFrame’s index. Provided integer column is ignored and excluded from result since an integer index is not used to calculate the rolling window.\n",
    "\n",
    "    axis : int or str, default 0\n",
    "    closed : str, default None\n",
    "    Make the interval closed on the ‘right’, ‘left’, ‘both’ or ‘neither’ endpoints. For offset-based windows, it defaults to ‘right’. For fixed windows, defaults to ‘both’. Remaining cases not implemented for fixed windows.\n",
    "\n",
    "- `pandas.DataFrame.reset_index` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html)\n",
    "\n",
    "`DataFrame.reset_index(self, level=None, drop=False, inplace=False, col_level=0, col_fill='')`\n",
    "\n",
    "Reset the index, or a level of it.\n",
    "\n",
    "Reset the index of the DataFrame, and use the default one instead. If the DataFrame has a MultiIndex, this method can remove one or more levels.\n",
    "\n",
    "    level : int, str, tuple, or list, default None\n",
    "    Only remove the given levels from the index. Removes all levels by default.\n",
    "\n",
    "    drop : bool, default False\n",
    "    Do not try to insert index into dataframe columns. This resets the index to the default integer index.\n",
    "\n",
    "    inplace : bool, default False\n",
    "    Modify the DataFrame in place (do not create a new object).\n",
    "\n",
    "    col_level : int or str, default 0\n",
    "    If the columns have multiple levels, determines which level the labels are inserted into. By default it is inserted into the first level.\n",
    "\n",
    "    col_fill : object, default ‘’\n",
    "    If the columns have multiple levels, determines how the other levels are named. If None then the index name is repeated.\n",
    "    \n",
    "- `pandas.DataFrame.sort_index` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_index.html)\n",
    "\n",
    "`DataFrame.sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, by=None)`\n",
    "\n",
    "Sort object by labels (along an axis).\n",
    "\n",
    "    axis : {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "    The axis along which to sort. The value 0 identifies the rows, and 1 identifies the columns.\n",
    "\n",
    "    level : int or level name or list of ints or list of level names\n",
    "    If not None, sort on values in specified index level(s).\n",
    "\n",
    "    ascending : bool, default True\n",
    "    Sort ascending vs. descending.\n",
    "\n",
    "    inplace : bool, default False\n",
    "    If True, perform operation in-place.\n",
    "\n",
    "    kind : {‘quicksort’, ‘mergesort’, ‘heapsort’}, default ‘quicksort’\n",
    "    Choice of sorting algorithm. See also ndarray.np.sort for more information. mergesort is the only stable algorithm. For DataFrames, this option is only applied when sorting on a single column or label.\n",
    "\n",
    "    na_position : {‘first’, ‘last’}, default ‘last’\n",
    "    Puts NaNs at the beginning if first; last puts NaNs at the end. Not implemented for MultiIndex.\n",
    "\n",
    "    sort_remaining : bool, default True\n",
    "    If True and sorting by level and index is multilevel, sort by other levels too (in order) after sorting by specified level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series and DatetimeIndex\n",
    "\n",
    "### 日時のデータの作成と操作\n",
    "\n",
    "難易度: *easy/medium*\n",
    "\n",
    "pandas は日時の取り扱いに長けている。このセクションではその機能を見ていこう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**33.** 2015 年の business day (平日) の DatatimeIndex を作りなさい。そして、それを乱数の Series のインデックスとしなさい。この Series を 's' と呼ぶことにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = pd.date_range('2015-01-01', '2015-12-31', freq='B')\n",
    "s = pd.Series(np.random.random(len(dti)), index=dti)\n",
    "print(s[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas.date_range` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html)\n",
    "\n",
    "`pandas.date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, closed=None, **kwargs)`\n",
    "\n",
    "Return a fixed frequency DatetimeIndex.\n",
    "\n",
    "    start : str or datetime-like, optional\n",
    "    Left bound for generating dates.\n",
    "\n",
    "    end : str or datetime-like, optional\n",
    "    Right bound for generating dates.\n",
    "\n",
    "    periods : integer, optional\n",
    "    Number of periods to generate.\n",
    "\n",
    "    freq : str or DateOffset, default ‘D’\n",
    "    Frequency strings can have multiples, e.g. ‘5H’. See here for a list of frequency aliases.\n",
    "\n",
    "    tz : str or tzinfo, optional\n",
    "    Time zone name for returning localized DatetimeIndex, for example ‘Asia/Hong_Kong’. By default, the resulting DatetimeIndex is timezone-naive.\n",
    "\n",
    "    normalize : bool, default False\n",
    "    Normalize start/end dates to midnight before generating date range.\n",
    "\n",
    "    name : str, default None\n",
    "    Name of the resulting DatetimeIndex.\n",
    "\n",
    "    closed : {None, ‘left’, ‘right’}, optional\n",
    "    Make the interval closed with respect to the given frequency to the ‘left’, ‘right’, or both sides (None, the default).\n",
    "\n",
    "    **kwargs\n",
    "    For compatibility. Has no effect on the result.\n",
    "    \n",
    "- DatetimeIndex の freq の設定は[こちら](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**34.** `s` の中で水曜日の値の和を計算しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s.index.weekday == 2].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`index.weekday` の曜日と数字の対応は\n",
    "- Monday    : 0\n",
    "- Tuesday   : 1\n",
    "- Wednesday : 2\n",
    "- Thursday  : 3\n",
    "- Friday    : 4\n",
    "- Saturdary : 5\n",
    "- Sunday    : 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**35.** `s` の中で月ごとの平均を計算しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.resample('M').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.resample` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html)\n",
    "\n",
    "`DataFrame.resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)`\n",
    "\n",
    "Resample time-series data.\n",
    "\n",
    "Convenience method for frequency conversion and resampling of time series. Object must have a datetime-like index (DatetimeIndex, PeriodIndex, or TimedeltaIndex), or pass datetime-like values to the on or level keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**36.** ４ヶ月ごとに最大値を有する日にちを取得しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( s.groupby(pd.Grouper(freq='4M')).idxmax() )\n",
    "print( s.groupby(pd.Grouper(freq='4M')).max() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.Grouper` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Grouper.html)\n",
    "\n",
    "`class pandas.Grouper(key=None, level=None, freq=None, axis=0, sort=False)`\n",
    "\n",
    "A Grouper allows the user to specify a groupby instruction for a target object\n",
    "\n",
    "This specification will select a column via the key parameter, or if the level and/or axis parameters are given, a level of the index of the target object.\n",
    "\n",
    "If axis and/or level are passed as keywords to both Grouper and groupby, the values passed to Grouper take precedence.\n",
    "\n",
    "    key : string, defaults to None\n",
    "    groupby key, which selects the grouping column of the target\n",
    "\n",
    "    level : name/number, defaults to None\n",
    "    the level for the target index\n",
    "\n",
    "    freq : string / frequency object, defaults to None\n",
    "    This will groupby the specified frequency if the target selection (via key or level) is a datetime-like object. For full specification of available frequencies, please see [here](http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).\n",
    "\n",
    "    axis : number/name of the axis, defaults to 0\n",
    "    sort : boolean, default to False\n",
    "    whether to sort the resulting labels\n",
    "\n",
    "    closed : {‘left’ or ‘right’}\n",
    "    Closed end of interval. Only when freq parameter is passed.\n",
    "\n",
    "    label : {‘left’ or ‘right’}\n",
    "    Interval boundary to use for labeling. Only when freq parameter is passed.\n",
    "\n",
    "    convention : {‘start’, ‘end’, ‘e’, ‘s’}\n",
    "    If grouper is PeriodIndex and freq parameter is passed.\n",
    "\n",
    "    base : int, default 0\n",
    "    Only when freq parameter is passed.\n",
    "\n",
    "    loffset : string, DateOffset, timedelta object\n",
    "    Only when freq parameter is passed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**37.** 2015年と2016年について、毎月第３木曜日の DatetimeIndex を作りなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.date_range('2015-01-01', '2016-12-31', freq='WOM-3THU')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのクリーニング\n",
    "\n",
    "### DataFrame を扱いやすいように加工する\n",
    "\n",
    "難易度: *easy/medium*\n",
    "\n",
    "与えられたデータに不適切な文字が入っていたり、形式がバラバラだったり、欠損があったりするのは日常茶飯事である。\n",
    "そのようなデータに対して、分析できるように整えるにはどうすればいいか。\n",
    "\n",
    "このセクションでは、そのような綺麗でないデータを扱う。\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', \n",
    "                               'Budapest_PaRis', 'Brussels_londOn'],\n",
    "              'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
    "              'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
    "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', \n",
    "                               '12. Air France', '\"Swiss Air\"']})\n",
    "```\n",
    "(It's some flight data I made up; it's not meant to be accurate in any way.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', \n",
    "                               'Budapest_PaRis', 'Brussels_londOn'],\n",
    "              'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
    "              'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
    "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', \n",
    "                               '12. Air France', '\"Swiss Air\"']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**38.** 'FlightNumber' カラムには欠損値がある。このカラムの数字は 10 ずつ増加しているので 10055 と 10075 が置き換えられるべき値である。これらの欠損を補間し、カラムのデータ型を int 型にしなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FlightNumber'] = df['FlightNumber'].interpolate().astype(int)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.interpolate` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html)\n",
    "\n",
    "`DataFrame.interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', limit_area=None, downcast=None, **kwargs)`\n",
    "\n",
    "Interpolate values according to different methods.\n",
    "\n",
    "Please note that only `method='linear'` is supported for DataFrame/Series with a MultiIndex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**39.** 'From\\_To' カラムは2つに分割したほうがよい。アンダースコア '\\_' で文字を区切り、仮の DataFrame を作り、ふさわしいカラム名を付けなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df['From_To'].str.split('_', expand=True)\n",
    "tmp.columns = ['From', 'To']\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.Series.str.split` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html)\n",
    "\n",
    "`Series.str.split(self, pat=None, n=-1, expand=False)`\n",
    "\n",
    "Split strings around given separator/delimiter.\n",
    "\n",
    "Splits the string in the Series/Index from the beginning, at the specified delimiter string. Equivalent to `str.split()`.\n",
    "\n",
    "    pat : str, optional\n",
    "    String or regular expression to split on. If not specified, split on whitespace.\n",
    "\n",
    "    n : int, default -1 (all)\n",
    "    Limit number of splits in output. None, 0 and -1 will be interpreted as return all splits.\n",
    "\n",
    "    expand : bool, default False\n",
    "    Expand the splitted strings into separate columns.\n",
    "        - If True, return DataFrame/MultiIndex expanding dimensionality.\n",
    "        - If False, return Series/Index, containing lists of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**40.** 前問で得られた都市名は大文字と小文字が混じっている。これらを初めの文字だけ大文字の状態にしなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['From'] = tmp['From'].str.capitalize()\n",
    "tmp['To'] = tmp['To'].str.capitalize()\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.Series.str.capitalize` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.capitalize.html)\n",
    "\n",
    "`Series.str.capitalize(self)`\n",
    "\n",
    "Convert strings in the Series/Index to be capitalized.\n",
    "\n",
    "Equivalent to [str.capitalize()](https://docs.python.org/3/library/stdtypes.html#str.capitalize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**41.** Delete the From_To column from `df` and attach the temporary DataFrame from the previous questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('From_To', axis=1).join(tmp)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas.DataFrame.drop` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)\n",
    "\n",
    "`DataFrame.drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')`\n",
    "\n",
    "Drop specified labels from rows or columns.\n",
    "\n",
    "Remove rows or columns by specifying label names and corresponding axis, or by specifying directly index or column names. When using a multi-index, labels on different levels can be removed by specifying the level.\n",
    "\n",
    "    labels : single label or list-like\n",
    "    Index or column labels to drop.\n",
    "\n",
    "    axis : {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "    Whether to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’).\n",
    "\n",
    "    index : single label or list-like\n",
    "    Alternative to specifying axis (labels, axis=0 is equivalent to index=labels).\n",
    "\n",
    "    New in version 0.21.0.\n",
    "\n",
    "    columns : single label or list-like\n",
    "    Alternative to specifying axis (labels, axis=1 is equivalent to columns=labels).\n",
    "\n",
    "    New in version 0.21.0.\n",
    "\n",
    "    level : int or level name, optional\n",
    "    For MultiIndex, level from which the labels will be removed.\n",
    "\n",
    "    inplace : bool, default False\n",
    "    If True, do operation inplace and return None.\n",
    "\n",
    "    errors : {‘ignore’, ‘raise’}, default ‘raise’\n",
    "    If ‘ignore’, suppress error and only existing labels are dropped.\n",
    "    \n",
    "- `pandas.DataFrame.join` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)\n",
    "\n",
    "`DataFrame.join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False)`\n",
    "\n",
    "Join columns of another DataFrame.\n",
    "\n",
    "Join columns with other DataFrame either on index or on a key column. Efficiently join multiple DataFrame objects by index at once by passing a list.    \n",
    "\n",
    "    other : DataFrame, Series, or list of DataFrame\n",
    "    Index should be similar to one of the columns in this one. If a Series is passed, its name attribute must be set, and that will be used as the column name in the resulting joined DataFrame.\n",
    "\n",
    "    on : str, list of str, or array-like, optional\n",
    "    Column or index level name(s) in the caller to join on the index in other, otherwise joins index-on-index. If multiple values given, the other DataFrame must have a MultiIndex. Can pass an array as the join key if it is not already contained in the calling DataFrame. Like an Excel VLOOKUP operation.\n",
    "\n",
    "    how : {‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘left’\n",
    "    How to handle the operation of the two objects.\n",
    "        - left: use calling frame’s index (or column if on is specified)\n",
    "        - right: use other’s index.\n",
    "        - outer: form union of calling frame’s index (or column if on is specified) with other’s index, and sort it. lexicographically.\n",
    "        - inner: form intersection of calling frame’s index (or column if on is specified) with other’s index, preserving the order of the calling’s one.\n",
    "        \n",
    "    lsuffix : str, default ‘’\n",
    "    Suffix to use from left frame’s overlapping columns.\n",
    "\n",
    "    rsuffix : str, default ‘’\n",
    "    Suffix to use from right frame’s overlapping columns.\n",
    "\n",
    "    sort : bool, default False\n",
    "    Order result DataFrame lexicographically by the join key. If False, the order of the join key depends on the join type (how keyword)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**42**. 'Airline' カラムには航空会社の名前の他に余計な点や記号が混じっている。'Airline' カラムから航空会社の名前だけを取得しなさい。すなわち。`'(British Airways. )'` から `'British Airways'`を抜き出しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Airline'] = df['Airline'].str.extract('([a-zA-Z\\s]+)')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas.Series.str.extract` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extract.html)\n",
    "\n",
    "`Series.str.extract(self, pat, flags=0, expand=True)`\n",
    "\n",
    "Extract capture groups in the regex `pat` as columns in a DataFrame.\n",
    "\n",
    "For each subject string in the Series, extract groups from the first match of regular expression `pat`.\n",
    "\n",
    "    pat : str\n",
    "    Regular expression pattern with capturing groups.\n",
    "\n",
    "    flags : int, default 0 (no flags)\n",
    "    Flags from the re module, e.g. re.IGNORECASE, that modify regular expression matching for things like case, spaces, etc. For more details, see re.\n",
    "\n",
    "    expand : bool, default True\n",
    "    If True, return DataFrame with one column per capture group. If False, return a Series/Index if there is one capture group or DataFrame if there are multiple capture groups.\n",
    "    \n",
    "- [正規表現 regular expression](https://murashun.jp/blog/20190215-01.html#chapter-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正規表現 `'([a-zA-Z\\s]+)'` の説明\n",
    "\n",
    "- `[a-z]` : 小文字のアルファベットのいずれか一文字\n",
    "- `[A-Z]` : 大文字のアルファベットのいずれか一文字\n",
    "- `\\s` : スペース\n",
    "- `[a-zA-Z\\s]` : アルファベットまたはスペースのいずれか一文字\n",
    "- `([a-zA-Z\\s]+)` : アルファベットまたはスペースのいずれか一文字が1回以上続く\n",
    "\n",
    "`str.extract('([a-zA-Z\\s]+)')` を実行すると、アルファベットまたはスペースに始まり、アルファベットでもスペースでもない文字の直前までの文字列が検出される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**43**. 'RecentDelays' カラムにはリスト形式のデータが入っている。そのリストの値を順番に個別のカラムに分けたい。ただし、該当の値が存在しない場合は NaN を入力する。\n",
    "\n",
    "'RecentDelays' カラムのデータを `delays` という名前の Series に変換し、そこから `delay_1`, `delay_2`, etc. というカラムを作りなさい。そして、不要な 'RecentDelays' カラムを削除しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = df['RecentDelays'].apply(pd.Series)\n",
    "delays.columns = ['delay_{}'.format(n) for n in range(1, len(delays.columns)+1)]\n",
    "df = df.drop('RecentDelays', axis=1).join(delays)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.apply` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html)\n",
    "\n",
    "`DataFrame.apply(self, func, axis=0, broadcast=None, raw=False, reduce=None, result_type=None, args=(), **kwds)`\n",
    "\n",
    "Apply a function along an axis of the DataFrame.\n",
    "\n",
    "Objects passed to the function are Series objects whose index is either the DataFrame’s index (axis=0) or the DataFrame’s columns (axis=1). By default (result_type=None), the final return type is inferred from the return type of the applied function. Otherwise, it depends on the result_type argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## マルチインデックスの利用\n",
    "\n",
    "### インデックスを追加して DataFrame を使いやすくする\n",
    "\n",
    "難易度: *medium*\n",
    "\n",
    "これまでは一つのインデックスしかもたない DataFrame を扱ってきた。しかし、pandas では複数のインデックス (MultiIndex) を利用することができる。これは正に Series や DataFrame に新たな次元を追加するようなものである。例えば、1次元配列である Series に対して、MultiIndex を使うことで 2 次元の DataFrame のように扱うことができる。\n",
    "\n",
    "このセクションでは、MultiIndex がデータ分析の中でどのように活かされるかを見ていく。\n",
    "\n",
    "ウォーミングアップとして、2つのインデックスをもつ Series を作ってみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**44**. `letters = ['A', 'B', 'C']` と `numbers = list(range(10))` の 2 つのリストが与えられたとき、2 つの直積から MultiIndex を作りなさい。\n",
    "そして、その MultiIndex を乱数の Series のインデックスとしなさい。この Series を `s` と呼ぶことにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['A', 'B', 'C']\n",
    "numbers = list(range(10))\n",
    "mi = pd.MultiIndex.from_product([letters, numbers])\n",
    "s = pd.Series(np.random.random(mi.size), index=mi)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas.MultiIndex` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.MultiIndex.html)\n",
    "\n",
    "`class pandas.MultiIndex`\n",
    "\n",
    "A multi-level, or hierarchical, index object for pandas objects.\n",
    "\n",
    "- `pandas.MultiIndex.from_product` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.MultiIndex.from_product.html)\n",
    "\n",
    "`classmethod MultiIndex.from_product(iterables, sortorder=None, names=None)`\n",
    "\n",
    "Make a MultiIndex from the cartesian product of multiple iterables.\n",
    "\n",
    "    iterables : list / sequence of iterables\n",
    "    Each iterable has unique labels for each level of the index.\n",
    "\n",
    "    sortorder : int or None\n",
    "    Level of sortedness (must be lexicographically sorted by that level).\n",
    "\n",
    "    names : list / sequence of str, optional\n",
    "    Names for the levels in the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**45.** `s` のインデックスが辞書順にソートされているかチェックしなさい。(辞書順になっていることは MultiIndex が正しく機能するために必要である。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index.is_lexsorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.MultiIndex.is_lexsorted` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.MultiIndex.is_lexsorted.html)\n",
    "\n",
    "`MultiIndex.is_lexsorted(self)`\n",
    "\n",
    "Return True if the codes are lexicographically sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**46**. `s` の第 ２ レベルのインデックスが `1, 3, 6` のものを選択しなさい。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[:, [1, 3, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**47**. Series `s` を次のようにスライスしなさい。; 第 １ レベルのインデックスに対してラベル 'B' まで、第 ２ レベルのインデックスに対して `5` 以降。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[:'B', 5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**48**. `s` の第 １ レベルのインデックスごとに和をとりなさい。(すなわち、'A', 'B', 'C' ごとの和を計算しなさい。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sum(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 別解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**49**. `sum()` や他の関数が `level` の引数をとらないと仮定しましょう。`s.sum(level=1)` と同じ結果を得るにはどうすればいいですか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.unstack().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.unstack` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.unstack.html)\n",
    "\n",
    "`DataFrame.unstack(self, level=-1, fill_value=None)`\n",
    "\n",
    "Pivot a level of the (necessarily hierarchical) index labels, returning a DataFrame having a new level of column labels whose inner-most level consists of the pivoted index labels.\n",
    "\n",
    "If the index is not a MultiIndex, the output will be a Series (the analogue of stack when the columns are not a MultiIndex).\n",
    "\n",
    "The level involved will automatically get sorted.\n",
    "\n",
    "    level : int, string, or list of these, default -1 (last level)\n",
    "    Level(s) of index to unstack, can pass level name\n",
    "\n",
    "    fill_value : replace NaN with this value if the unstack produces\n",
    "    missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**50**. `s` の MultiIndex のレベルを入れ替えて `(letters, numbers)` の順にしなさい。入れ替えた結果は辞書順になっていますか？もしなっていなかったら、辞書順にソートしなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = s.swaplevel(0,1)\n",
    "print( t.index.is_lexsorted() )\n",
    "t = t.sort_index()\n",
    "print( t.index.is_lexsorted() )\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.swaplevel` [manual](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.swaplevel.html)\n",
    "\n",
    "`DataFrame.swaplevel(self, i=-2, j=-1, axis=0)`\n",
    "\n",
    "Swap levels `i` and `j` in a MultiIndex on a particular axis.\n",
    "\n",
    "    i, j : int, string (can be mixed)\n",
    "    Level of index to be swapped. Can pass level name as string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マインスイーパー\n",
    "\n",
    "### Generate the numbers for safe squares in a Minesweeper grid\n",
    "\n",
    "難易度: *medium* to *hard*\n",
    "\n",
    "If you've ever used an older version of Windows, there's a good chance you've played with [Minesweeper](https://en.wikipedia.org/wiki/Minesweeper_(video_game). If you're not familiar with the game, imagine a grid of squares: some of these squares conceal a mine. If you click on a mine, you lose instantly. If you click on a safe square, you reveal a number telling you how many mines are found in the squares that are immediately adjacent. The aim of the game is to uncover all squares in the grid that do not contain a mine.\n",
    "\n",
    "In this section, we'll make a DataFrame that contains the necessary data for a game of Minesweeper: coordinates of the squares, whether the square contains a mine and the number of mines found on adjacent squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**51**. Let's suppose we're playing Minesweeper on a 5 by 4 grid, i.e.\n",
    "```\n",
    "X = 5\n",
    "Y = 4\n",
    "```\n",
    "To begin, generate a DataFrame `df` with two columns, `'x'` and `'y'` containing every coordinate for this grid. That is, the DataFrame should start:\n",
    "```\n",
    "   x  y\n",
    "0  0  0\n",
    "1  0  1\n",
    "2  0  2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 次のコードは `pandas.tools` がないと言われて動かない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 5\n",
    "Y = 4\n",
    "p = pd.tools.util.cartesian_product([np.arange(X), np.arange(Y)])\n",
    "#p = pd.MultiIndex.from_product([np.arange(X), np.arange(Y)])\n",
    "print(p)\n",
    "print(np.array(p))\n",
    "#df = pd.DataFrame(np.asarray(p).T, columns=['x', 'y'])\n",
    "df = pd.DataFrame(np.asarray(p).T)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**52**. For this DataFrame `df`, create a new column of zeros (safe) and ones (mine). The probability of a mine occuring at each location should be 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mine'] = np.random.binomial(1, 0.4, X*Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**53**. Now create a new column for this DataFrame called `'adjacent'`. This column should contain the number of mines found on adjacent squares in the grid. \n",
    "\n",
    "(E.g. for the first row, which is the entry for the coordinate `(0, 0)`, count how many mines are found on the coordinates `(0, 1)`, `(1, 0)` and `(1, 1)`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is one way to solve using merges.\n",
    "# It's not necessary the optimal way, just \n",
    "# the solution I thought of first...\n",
    "\n",
    "df['adjacent'] = \\\n",
    "    df.merge(df + [ 1,  1, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [ 1, -1, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [-1,  1, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [-1, -1, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [ 1,  0, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [-1,  0, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [ 0,  1, 0], on=['x', 'y'], how='left')\\\n",
    "      .merge(df + [ 0, -1, 0], on=['x', 'y'], how='left')\\\n",
    "       .iloc[:, 3:]\\\n",
    "        .sum(axis=1)\n",
    "        \n",
    "# An alternative solution is to pivot the DataFrame \n",
    "# to form the \"actual\" grid of mines and use convolution.\n",
    "# See https://github.com/jakevdp/matplotlib_pydata2013/blob/master/examples/minesweeper.py\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "mine_grid = df.pivot_table(columns='x', index='y', values='mine')\n",
    "counts = convolve2d(mine_grid.astype(complex), np.ones((3, 3)), mode='same').real.astype(int)\n",
    "df['adjacent'] = (counts - mine_grid).ravel('F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**54**. For rows of the DataFrame that contain a mine, set the value in the `'adjacent'` column to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['mine'] == 1, 'adjacent'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**55**. Finally, convert the DataFrame to grid of the adjacent mine counts: columns are the `x` coordinate, rows are the `y` coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('mine', axis=1)\\\n",
    "  .set_index(['y', 'x']).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可視化, 描画\n",
    "\n",
    "### データの傾向やパターンを可視化する\n",
    "\n",
    "難易度: *medium*\n",
    "\n",
    "DataFrame に入っているデータをよく理解するためには、可視化することが不可欠です。可視化によって傾向や異常値が見つかります。可視化の機能は pandas に組み込まれていて、以下のパズルではどんなことができるのか見ていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**56.** pandas は可視化ライブラリの matplotlib と共に開発が進められ、とてもわかりやすく DataFrame の可視化ができます。ノートブック環境での可視化では以下のような定型文が必要になります。\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "```\n",
    "\n",
    "matplotlib は pandas のデータを可視化することができるライブラリで、一般的に `plt` という名前で扱われます。\n",
    "\n",
    "`%matplotlib inline` はグラフをノートブック上に表示させる命令です。これがないとグラフが別ウィンドーで表示されます。\n",
    "\n",
    "\n",
    "`plt.style.use('ggplot')` は定評のある R の ggplot パッケージのスタイルで描画する命令です。\n",
    "\n",
    "初めに、デフォルトのマーカーの替わりに黒いバツ印 (X) を使って、乱数のデータのスキャッタープロットを作ってみましょう。\n",
    "\n",
    "`df = pd.DataFrame({\"xs\":[1,5,2,8,1], \"ys\":[4,2,1,9,6]})`\n",
    "\n",
    "困ったらこちらを参照してください! [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "df = pd.DataFrame({\"xs\":[1,5,2,8,1], \"ys\":[4,2,1,9,6]})\n",
    "plt.scatter(df['xs'], df['ys'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**57.** DataFrame の列を使って色とサイズを変更することもできます。ビルはその日の自分の調子はどうか、朝にコーヒーを飲んだか、仕事でのパフォーマンはどうだったかをずっと追跡しています。DataFrame の 4 つの特徴を取り入れたプロットを作りなさい。\n",
    "\n",
    "(ヒント: プロットが見えないようなことがあれば、そのプロットしたい Series に 10 程度の数を掛け算してみなさい。)\n",
    "\n",
    "*グラフは綺麗である必要はありません。このパズルはデータの可視化コースでありません。*\n",
    "\n",
    "```\n",
    "df = pd.DataFrame({\"productivity\":[5,2,3,1,4,5,6,7,8,3,4,8,9],\n",
    "                   \"hours_in\"    :[1,9,6,5,3,9,2,9,1,7,4,2,2],\n",
    "                   \"happiness\"   :[2,1,3,2,3,1,2,3,1,2,2,1,3],\n",
    "                   \"caffienated\" :[0,0,1,1,0,0,0,0,1,1,0,1,0]})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"productivity\":[5,2,3,1,4,5,6,7,8,3,4,8,9],\n",
    "                   \"hours_in\"    :[1,9,6,5,3,9,2,9,1,7,4,2,2],\n",
    "                   \"happiness\"   :[2,1,3,2,3,1,2,3,1,2,2,1,3],\n",
    "                   \"caffienated\" :[0,0,1,1,0,0,0,0,1,1,0,1,0]})\n",
    "\n",
    "df.plot.scatter('hours_in', 'productivity', c=df['caffienated'], s=df['happiness']*30)\n",
    "#plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**58.** 複数種類のデータをプロットしたいときはどうすればいいでしょうか？ pandas は matplotlib の *Axis* オブジェクトを扱うことができます。月ごとの収益の bar プロットと広告費の line プロットを作りなさい。(金額は 100 万円単位である。)\n",
    "```\n",
    "df = pd.DataFrame({\"revenue\":[57,68,63,71,72,90,80,62,59,51,47,52],\n",
    "                   \"advertising\":[2.1,1.9,2.7,3.0,3.6,3.2,2.7,2.4,1.8,1.6,1.3,1.9],\n",
    "                   \"month\":range(12)\n",
    "                  })\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"revenue\":[57,68,63,71,72,90,80,62,59,51,47,52],\n",
    "                   \"advertising\":[2.1,1.9,2.7,3.0,3.6,3.2,2.7,2.4,1.8,1.6,1.3,1.9],\n",
    "                   \"month\":range(12)\n",
    "                  })\n",
    "\n",
    "ax = df.plot.bar(\"month\", \"revenue\", color='blue')\n",
    "df.plot.line(\"month\", \"advertising\", secondary_y=True, ax=ax)\n",
    "ax.set_xlim((-1, 12))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまででローソク足チャート candlestick chart を作る準備が整いました。ローソク足チャートは株価データの分析に広く使われているツールです。ローソク足チャートは株価の始値、終値、最高価格、最低価格を示すことができます。ローソク (バーの太い部分) の色は終値が始値より高ければ緑、低ければ赤です。\n",
    "\n",
    "![Candlestick Example](img/candle.jpg)\n",
    "\n",
    "このローソク足チャートは元々、pandas での可視化の課題として考え出されたものだが、pandas のメソッドだけでは実現できないものです。\n",
    "もしも matplotlib に不慣れな場合、pandas を使ってデータを正しいフォーマットにしている限り、チャートをプロットすることができます。\n",
    "\n",
    "初めのステップは pandas の time-series のグルーピングの機能を使ってデータを正しいフォーマットで読み込むことです。\n",
    "1 本のローソクがそれぞれのデータの 1 時間を表すものとします。自分で集計関数を使って 始値/最大価格/最低価格/終値 を書き出すこともできますが、pandas にはそれをしてくれる組み込み関数があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記のセルのコードではヘルパー関数 (def ...(): の関数) を含んでいます。\n",
    "\n",
    "仮想的な株価が売られた価格と売りに出された時間を含む DataFrame を作る `day_stock_data()` を呼び出します。\n",
    "そして、ローソク足チャートを表示するために集計およびフォーマットされた株価データを `plot_candlestick(df)` に渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def float_to_time(x):\n",
    "    return str(int(x)) + \":\" + str(int(x%1 * 60)).zfill(2) + \":\" + str(int(x*60 % 1 * 60)).zfill(2)\n",
    "\n",
    "def day_stock_data():\n",
    "    #NYSE is open from 9:30 to 4:00\n",
    "    time = 9.5\n",
    "    price = 100\n",
    "    results = [(float_to_time(time), price)]\n",
    "    while time < 16:\n",
    "        elapsed = np.random.exponential(.001)\n",
    "        time += elapsed\n",
    "        if time > 16:\n",
    "            break\n",
    "        price_diff = np.random.uniform(.999, 1.001)\n",
    "        price *= price_diff\n",
    "        results.append((float_to_time(time), price))\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(results, columns = ['time','price'])\n",
    "    df.time = pd.to_datetime(df.time)\n",
    "    return df\n",
    "\n",
    "#Don't read me unless you get stuck!\n",
    "def plot_candlestick(agg):\n",
    "    \"\"\"\n",
    "    agg is a DataFrame which has a DatetimeIndex and five columns: [\"open\",\"high\",\"low\",\"close\",\"color\"]\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    for time in agg.index:\n",
    "        ax.plot([time.hour] * 2, agg.loc[time, [\"high\",\"low\"]].values, color = \"black\")\n",
    "        ax.plot([time.hour] * 2, agg.loc[time, [\"open\",\"close\"]].values, color = agg.loc[time, \"color\"], linewidth = 10)\n",
    "\n",
    "    ax.set_xlim((8,16))\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.set_xlabel(\"Hour\")\n",
    "    ax.set_title(\"OHLC of Stock Value During Trading Day\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**59.** 前問で作ったランダムな株価データに対して、1 時間ごとの始値, 最高価格, 最低価格, 終値を表示するように集計および再フォーマットしなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## データフレームの確認\n",
    "df = day_stock_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"time\", inplace = True)\n",
    "agg = df.resample(\"H\").ohlc()\n",
    "agg.columns = agg.columns.droplevel()\n",
    "agg[\"color\"] = (agg.close > agg.open).map({True:\"green\",False:\"red\"})\n",
    "agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**60.** 前問までで正しくフォーマットされたデータを準備することができました。自力でローソク足チャートを描いてみましょう。\n",
    "行き詰まったら、上で使った `plot_candlestick(df)` を利用するか、matplotlib の [`plot` documentation](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.plot.html) を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candlestick(agg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
